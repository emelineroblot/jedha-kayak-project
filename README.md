# ğŸ–ï¸ Projet Kayak - Recommandation de Destinations

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Objectifs](#objectifs)
- [Architecture du Projet](#architecture-du-projet)
- [Ã‰tapes du Projet](#Ã©tapes-du-projet)
- [Installation](#installation)
- [Auteur](#auteur)

---

## ğŸ¯ Vue d'ensemble

Ce projet analyse **35 villes franÃ§aises** pour identifier les **Top 5 destinations** selon :
- â˜€ï¸ **Conditions mÃ©tÃ©orologiques** (tempÃ©rature, prÃ©cipitations, ensoleillement)
- ğŸ¨ **DisponibilitÃ© et qualitÃ© des hÃ©bergements** (notes, prix, Ã©quipements)
- ğŸ¯ **Score combinÃ©** intÃ©grant mÃ©tÃ©o, qualitÃ© et prix

Le systÃ¨me gÃ©nÃ¨re des **recommandations personnalisÃ©es** sous forme de :
- ğŸ“Š Tableaux de donnÃ©es structurÃ©s
- ğŸ—ºï¸ Cartes interactives gÃ©olocalisÃ©es
- ğŸ“ˆ Visualisations analytiques
- ğŸ“„ Rapport HTML complet
- â˜ï¸ **DÃ©ploiement cloud sur AWS**

---

## ğŸ¯ Objectifs

### Objectifs Principaux

1. âœ… **Collecter et traiter** les donnÃ©es mÃ©tÃ©orologiques de 35 villes franÃ§aises
2. âœ… **Identifier le Top 5** des destinations selon un score mÃ©tÃ©o composite
3. âœ… **RÃ©cupÃ©rer les offres d'hÃ©bergements** via l'API de Booking.com
4. âœ… **Fusionner et analyser** les donnÃ©es mÃ©tÃ©o + hÃ´tels
5. âœ… **CrÃ©er des visualisations** interactives et un rapport final
6. âœ… **DÃ©ployer sur AWS** (S3 + RDS PostgreSQL)

### KPIs

- **35 villes** analysÃ©es avec donnÃ©es mÃ©tÃ©o complÃ¨tes
- **Top 5 destinations** identifiÃ©es
- **75 hÃ´tels** rÃ©cupÃ©rÃ©s (15 par ville)
- **Score final** combinant mÃ©tÃ©o (40%), qualitÃ© (40%), prix (20%)
- **Cartes interactives** avec gÃ©olocalisation GPS
- **Rapport HTML** professionnel
- **Base de donnÃ©es PostgreSQL** hÃ©bergÃ©e sur AWS RDS
- **Fichiers accessibles publiquement** via AWS S3

---

## ğŸ—ï¸ Architecture du Projet
```
kayak_project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                                # DonnÃ©es brutes
â”‚   â”‚   â”œâ”€â”€ cities.csv                      # Liste des 35 villes
â”‚   â”‚   â”œâ”€â”€ weather_raw.csv                 # DonnÃ©es mÃ©tÃ©o brutes
â”‚   â”‚   â”œâ”€â”€ hotels_top5_all.csv             # Tous les hÃ´tels (Top 5)
â”‚   â”‚   â””â”€â”€ hotels/                         # CSV par ville
â”‚   â”‚       â”œâ”€â”€ hotels_marseille.csv
â”‚   â”‚       â”œâ”€â”€ hotels_cassis.csv
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ processed/                          # DonnÃ©es traitÃ©es
â”‚       â”œâ”€â”€ city_weather_scores.csv         # Scores mÃ©tÃ©o par ville
â”‚       â”œâ”€â”€ top5_destinations.csv           # Top 5 destinations
â”‚       â”œâ”€â”€ final_recommendations.csv       # Recommandations finales
â”‚       â”œâ”€â”€ top20_recommendations.csv       # Top 20 hÃ´tels
â”‚       â”œâ”€â”€ carte_tous_hotels.html          # Carte interactive complÃ¨te
â”‚       â”œâ”€â”€ carte_top20.html                # Carte Top 20
â”‚       â”œâ”€â”€ dashboard_complet.png           # Graphiques d'analyse
â”‚       â”œâ”€â”€ rapport_final.html              # Rapport complet
â”‚       â”œâ”€â”€ aws_s3_urls.txt                 # URLs S3 publiques
â”‚       â””â”€â”€ rds_import_report.txt           # Rapport import base de donnÃ©es
â”‚
â”œâ”€â”€ notebooks/                              # Notebooks Jupyter
â”‚   â”œâ”€â”€ 01_data_collection.ipynb            # Ã‰tape 1 : RÃ©cupÃ©ration des coordonnÃ©es gps des 35 villes
â”‚   â”œâ”€â”€ 02_data_weather.ipynb               # Ã‰tape 2 : RÃ©cupÃ©ration donnÃ©es mÃ©tÃ©o
â”‚   â”œâ”€â”€ 03_scoring_weather_cities.ipynb     # Ã‰tape 3 : Scoring du temps par ville en fonction critÃ¨res mÃ©tÃ©o 
â”‚   â”œâ”€â”€ 04_hotels_scraping.ipynb            # Ã‰tape 4 : Scraping hÃ´tels 
â”‚   â”œâ”€â”€ 05_hotels_cleaning.ipynb            # Ã‰tape 5 : Enrichissement donnÃ©es hÃ´tels
â”‚   â”œâ”€â”€ 06_fusion_meteo_hotels.ipynb        # Ã‰tape 6 : Fusion data hÃ´tels et mÃ©tÃ©o
â”‚   â”œâ”€â”€ 07_visualisations_rapport.ipynb     # Ã‰tape 7 : CrÃ©ation visualisations et rapport final
â”‚   â”œâ”€â”€ 08_aws_setup.ipynb                  # Ã‰tape 8 : Configuration AWS
â”‚   â”œâ”€â”€ 09_deploy_s3.ipynb                  # Ã‰tape 9 : DÃ©ploiement S3
â”‚   â”œâ”€â”€ 10_setup_rds.ipynb                  # Ã‰tape 10 : Configuration RDS
â”‚   â””â”€â”€ 11_import_data_rds.ipynb            # Ã‰tape 11 : Import donnÃ©es RDS
â”‚
â”œâ”€â”€ src/                                    # Scripts Python
â”‚   â”œâ”€â”€ fetch_results.py                    # Etape 2 scraping hÃ´tels
â”‚   â””â”€â”€ trigger_scrapping.py                # Etape 1 scraping hÃ´tels
â”‚
â”œâ”€â”€ requirements.txt                        # DÃ©pendances Python
â”œâ”€â”€ .env.example                            # Template variables d'environnement
â”œâ”€â”€ .gitignore                              # Fichiers ignorÃ©s par Git
â””â”€â”€ README.md                               # Ce fichier
```

---

## ğŸš€ Ã‰tapes du Projet

### âœ… **Ã‰tape 1 : Analyse MÃ©tÃ©orologique**

**Objectif** : Collecter et analyser les donnÃ©es mÃ©tÃ©o de 35 villes franÃ§aises.

**Actions** :
1. Collecte via API mÃ©tÃ©o (OpenWeatherMap)
2. Calcul d'un score composite pondÃ©rÃ© :
   - ğŸŒ¡ï¸ **TempÃ©rature** (30%) : optimal entre 20-28Â°C
   - â˜” **PrÃ©cipitations** (30%) : plus c'est faible, mieux c'est
   - â˜€ï¸ **Ensoleillement** (25%) : maximum d'heures de soleil
   - ğŸ’¨ **Vent** (15%) : faible vitesse prÃ©fÃ©rÃ©e

**RÃ©sultat** : Top 5 destinations identifiÃ©es

---

### âœ… **Ã‰tape 2 : Scraping des HÃ©bergements**

**Objectif** : RÃ©cupÃ©rer les offres d'hÃ©bergements pour le Top 5.

**Actions** :
1. Scraping via API Booking.com (BrightData)
2. RÃ©cupÃ©ration de ~15 hÃ´tels par ville
3. Extraction des donnÃ©es :
   - Nom, URL, note, prix
   - CoordonnÃ©es GPS (latitude, longitude)
   - Ã‰quipements, images
   - Nombre d'avis

**RÃ©sultat** : 75 hÃ´tels rÃ©cupÃ©rÃ©s avec 100% de donnÃ©es GPS

---

### âœ… **Ã‰tape 3 : Fusion et Recommandations**

**Objectif** : CrÃ©er un systÃ¨me de recommandation combinÃ©.

#### 3.1 Fusion des DonnÃ©es

**Actions** :
1. Merge des datasets mÃ©tÃ©o + hÃ´tels
2. Normalisation des scores sur Ã©chelle 0-10
3. Calcul du **score final** :
```
   Score Final = 0.40 Ã— Score MÃ©tÃ©o 
                + 0.40 Ã— Score HÃ´tel 
                + 0.20 Ã— Score Prix (inversÃ©)
```

#### 3.2 Visualisations et Rapport

**Actions** :
1. **Cartes interactives** (Folium) :
   - Tous les hÃ´tels gÃ©olocalisÃ©s
   - Top 20 avec marqueurs numÃ©rotÃ©s
   - Popups dÃ©taillÃ©s (score, prix, mÃ©tÃ©o)
   - LÃ©gende par code couleur

2. **Dashboard analytique** (8 graphiques) :
   - Distribution des scores par ville
   - Top 10 hÃ´tels
   - CorrÃ©lation qualitÃ©/prix
   - Impact mÃ©tÃ©o sur le score
   - RÃ©partition par type de propriÃ©tÃ©

3. **Rapport HTML interactif** :
   - Design moderne et responsive
   - Statistiques clÃ©s
   - Top 5 dÃ©taillÃ©
   - Cartes intÃ©grÃ©es
   - Graphiques d'analyse

---

### âœ… **Ã‰tape 4 : DÃ©ploiement AWS**

**Objectif** : DÃ©ployer les donnÃ©es et visualisations sur le cloud AWS.

#### 4.1 Configuration AWS

**Actions** :
1. Configuration des credentials AWS (Access Key, Secret Key)
2. VÃ©rification de la connexion S3 et RDS
3. Test des permissions IAM

---

#### 4.2 DÃ©ploiement S3

**Actions** :
1. Upload des fichiers vers S3 :
   - Rapport HTML final
   - Cartes interactives
   - Graphiques et dashboards
   - DonnÃ©es CSV
2. Configuration de l'accÃ¨s public via Bucket Policy
3. GÃ©nÃ©ration des URLs publiques

**RÃ©sultat** : 
```
ğŸ“„ Rapport Final : https://251107-140505-jedha-kayak-project.s3.eu-west-3.amazonaws.com/rapport_final.html
ğŸ—ºï¸ Carte ComplÃ¨te : https://251107-140505-jedha-kayak-project.s3.eu-west-3.amazonaws.com/cartes/carte_tous_hotels.html
ğŸ† Carte Top 20 : https://251107-140505-jedha-kayak-project.s3.eu-west-3.amazonaws.com/cartes/carte_top20.html
```

---

#### 4.3 Configuration RDS PostgreSQL

**Actions** :
1. Connexion Ã  l'instance RDS existante
2. CrÃ©ation du schÃ©ma de base de donnÃ©es :
   - Table `cities` : Informations des villes
   - Table `hotels` : Catalogue des hÃ´tels
   - Table `recommendations` : Recommandations finales
   - Table `weather_history` : Historique mÃ©tÃ©o
3. CrÃ©ation de vues SQL pour requÃªtes rapides :
   - `top_recommendations` : Classement complet
   - `city_statistics` : Statistiques par ville
   - `best_hotels_by_city` : Meilleurs hÃ´tels par ville

---

#### 4.4 Import des DonnÃ©es

**Actions** :
1. Import des villes (5 destinations)
2. Import des hÃ´tels (75 hÃ´tels)
3. Import des recommandations (74 entrÃ©es)
4. Import de l'historique mÃ©tÃ©o (5 enregistrements)
5. VÃ©rification de l'intÃ©gritÃ© des donnÃ©es

**Statistiques finales** :
```
âœ… 5 villes importÃ©es
âœ… 75 hÃ´tels importÃ©s
âœ… 74 recommandations importÃ©es
âœ… 5 enregistrements mÃ©tÃ©o
ğŸ’¾ Taille de la base : ~8 MB
```

---

## ğŸ’» Installation

### PrÃ©requis

- Python 3.8+
- pip
- Jupyter Notebook
- Compte BrightData (pour scraping Booking.com)
- Compte AWS (pour dÃ©ploiement cloud)

### Ã‰tapes
```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/emelineroblot/kayak_project.git
cd kayak_project

# 2. CrÃ©er un environnement virtuel
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env et ajouter :
# - ClÃ© API BrightData
# - Credentials AWS (Access Key, Secret Key)
# - Configuration RDS (Host, Database, User, Password)
```

---

## ğŸ‘¤ Auteur

**Emeline ROBLOT**
- ğŸŒ GitHub : [@emelineroblot](https://github.com/emelineroblot)
- ğŸ’¼ LinkedIn : [Emeline ROBLOT](https://linkedin.com/in/emeline-roblot)
- ğŸ“§ Email : emeline.roblot@emdigital.fr

---

**DerniÃ¨re mise Ã  jour** : Novembre 2025

**Status** : âœ… **PROJET COMPLET** - Toutes les Ã©tapes terminÃ©es (Ã‰tapes 1-4)

